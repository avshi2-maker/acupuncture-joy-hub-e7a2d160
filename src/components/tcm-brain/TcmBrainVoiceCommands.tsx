import { useState, useEffect, useRef, useCallback } from 'react';
import { Mic, MicOff, Volume2, Languages } from 'lucide-react';
import { cn } from '@/lib/utils';
import { useHapticFeedback } from '@/hooks/useHapticFeedback';
import { toast } from 'sonner';

export type TcmVoiceCommand = 
  | 'generate-summary'
  | 'save-to-patient'
  | 'export-session'
  | 'print-report'
  | 'share-whatsapp'
  | 'generate-audio'
  | 'start-session'
  | 'pause-session'
  | 'end-session'
  | 'clear-chat'
  | 'next-tab'
  | 'previous-tab';

interface TcmBrainVoiceCommandsProps {
  onCommand: (command: TcmVoiceCommand) => void;
  isSessionActive: boolean;
  wakeWord?: string;
  language?: 'en' | 'he';
}

// English voice commands
const ENGLISH_COMMANDS: Record<string, TcmVoiceCommand> = {
  'generate summary': 'generate-summary',
  'create summary': 'generate-summary',
  'summary': 'generate-summary',
  'summarize': 'generate-summary',
  'ai summary': 'generate-summary',
  'topic summary': 'generate-summary',
  'save to patient': 'save-to-patient',
  'save patient': 'save-to-patient',
  'save': 'save-to-patient',
  'save file': 'save-to-patient',
  'save record': 'save-to-patient',
  'export': 'export-session',
  'export session': 'export-session',
  'download': 'export-session',
  'download session': 'export-session',
  'print': 'print-report',
  'print report': 'print-report',
  'print session': 'print-report',
  'share whatsapp': 'share-whatsapp',
  'whatsapp': 'share-whatsapp',
  'send whatsapp': 'share-whatsapp',
  'share': 'share-whatsapp',
  'generate audio': 'generate-audio',
  'create audio': 'generate-audio',
  'make mp3': 'generate-audio',
  'audio': 'generate-audio',
  'mp3': 'generate-audio',
  'start session': 'start-session',
  'begin session': 'start-session',
  'start': 'start-session',
  'pause session': 'pause-session',
  'pause': 'pause-session',
  'end session': 'end-session',
  'stop session': 'end-session',
  'finish': 'end-session',
  'clear': 'clear-chat',
  'clear chat': 'clear-chat',
  'reset': 'clear-chat',
  'next tab': 'next-tab',
  'next': 'next-tab',
  'previous tab': 'previous-tab',
  'previous': 'previous-tab',
  'back': 'previous-tab',
};

// Hebrew voice commands
const HEBREW_COMMANDS: Record<string, TcmVoiceCommand> = {
  // Summary - ×¡×™×›×•×
  '×¡×™×›×•×': 'generate-summary',
  '×¦×•×¨ ×¡×™×›×•×': 'generate-summary',
  '×¡×›×': 'generate-summary',
  '×ª×¡×›×': 'generate-summary',
  '×¡×™×›×•× × ×•×©×': 'generate-summary',
  
  // Save - ×©××•×¨
  '×©××•×¨': 'save-to-patient',
  '×©××•×¨ ×œ××˜×•×¤×œ': 'save-to-patient',
  '×©××•×¨ ×§×•×‘×¥': 'save-to-patient',
  '×©××•×¨ ×œ×ª×™×§': 'save-to-patient',
  '×©××™×¨×”': 'save-to-patient',
  
  // Export - ×™×™×¦×•×
  '×™×™×¦×': 'export-session',
  '×™×™×¦×•×': 'export-session',
  '×”×•×¨×“': 'export-session',
  '×”×•×¨×“×”': 'export-session',
  
  // Print - ×”×“×¤×¡×”
  '×”×“×¤×¡': 'print-report',
  '×”×“×¤×¡×”': 'print-report',
  '×”×“×¤×¡ ×“×•×—': 'print-report',
  
  // WhatsApp - ×•×•××˜×¡××¤
  '×©×œ×— ×•×•××˜×¡××¤': 'share-whatsapp',
  '×•×•××˜×¡××¤': 'share-whatsapp',
  '×©×ª×£': 'share-whatsapp',
  '×©×™×ª×•×£': 'share-whatsapp',
  
  // Audio - ××•×“×™×•
  '×¦×•×¨ ××•×“×™×•': 'generate-audio',
  '××•×“×™×•': 'generate-audio',
  '×”×§×œ×˜×”': 'generate-audio',
  'mp3': 'generate-audio',
  
  // Session - ×˜×™×¤×•×œ
  '×”×ª×—×œ ×˜×™×¤×•×œ': 'start-session',
  '×”×ª×—×œ': 'start-session',
  '×”×ª×—×œ×”': 'start-session',
  '×¢×¦×•×¨': 'pause-session',
  '×”×©×”×”': 'pause-session',
  '×”×¤×¡×§×”': 'pause-session',
  '×¡×™×™× ×˜×™×¤×•×œ': 'end-session',
  '×¡×™×•×': 'end-session',
  '×¡×™×™×': 'end-session',
  
  // Clear - × ×§×”
  '× ×§×”': 'clear-chat',
  '× ×™×§×•×™': 'clear-chat',
  '××¤×¡': 'clear-chat',
  '××—×§': 'clear-chat',
  
  // Navigation - × ×™×•×•×˜
  '×”×‘×': 'next-tab',
  '×˜××‘ ×”×‘×': 'next-tab',
  '×§×“×™××”': 'next-tab',
  '×”×§×•×“×': 'previous-tab',
  '×˜××‘ ×§×•×“×': 'previous-tab',
  '××—×•×¨×”': 'previous-tab',
  '×—×–×•×¨': 'previous-tab',
};

const COMMAND_LABELS: Record<TcmVoiceCommand, { en: string; he: string }> = {
  'generate-summary': { en: 'ğŸ“ Generate Summary', he: 'ğŸ“ ×¦×•×¨ ×¡×™×›×•×' },
  'save-to-patient': { en: 'ğŸ’¾ Save to Patient', he: 'ğŸ’¾ ×©××•×¨ ×œ××˜×•×¤×œ' },
  'export-session': { en: 'ğŸ“¥ Export Session', he: 'ğŸ“¥ ×™×™×¦× ×˜×™×¤×•×œ' },
  'print-report': { en: 'ğŸ–¨ï¸ Print Report', he: 'ğŸ–¨ï¸ ×”×“×¤×¡ ×“×•×—' },
  'share-whatsapp': { en: 'ğŸ’¬ Share WhatsApp', he: 'ğŸ’¬ ×©×ª×£ ×‘×•×•××˜×¡××¤' },
  'generate-audio': { en: 'ğŸ”Š Generate MP3', he: 'ğŸ”Š ×¦×•×¨ ××•×“×™×•' },
  'start-session': { en: 'â–¶ï¸ Start Session', he: 'â–¶ï¸ ×”×ª×—×œ ×˜×™×¤×•×œ' },
  'pause-session': { en: 'â¸ï¸ Pause Session', he: 'â¸ï¸ ×”×©×”×” ×˜×™×¤×•×œ' },
  'end-session': { en: 'â¹ï¸ End Session', he: 'â¹ï¸ ×¡×™×™× ×˜×™×¤×•×œ' },
  'clear-chat': { en: 'ğŸ—‘ï¸ Clear Chat', he: 'ğŸ—‘ï¸ × ×§×” ×¦××˜' },
  'next-tab': { en: 'â¡ï¸ Next Tab', he: 'â¡ï¸ ×˜××‘ ×”×‘×' },
  'previous-tab': { en: 'â¬…ï¸ Previous Tab', he: 'â¬…ï¸ ×˜××‘ ×§×•×“×' },
};

export function TcmBrainVoiceCommands({ 
  onCommand, 
  isSessionActive,
  wakeWord = 'hey cm',
  language: initialLanguage = 'en'
}: TcmBrainVoiceCommandsProps) {
  const [isListening, setIsListening] = useState(false);
  const [isAwake, setIsAwake] = useState(false);
  const [lastCommand, setLastCommand] = useState<TcmVoiceCommand | null>(null);
  const [language, setLanguage] = useState<'en' | 'he'>(initialLanguage);
  const recognitionRef = useRef<SpeechRecognitionInterface | null>(null);
  const awakeTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const haptic = useHapticFeedback();

  const isSupported = typeof window !== 'undefined' && 
    ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window);

  const currentCommands = language === 'he' ? HEBREW_COMMANDS : ENGLISH_COMMANDS;
  const currentWakeWord = language === 'he' ? '×”×™×™ ×¡×™××' : wakeWord;

  const processTranscript = useCallback((transcript: string) => {
    const lowerTranscript = transcript.toLowerCase().trim();
    console.log('[TcmVoice] Transcript:', lowerTranscript, 'Language:', language);

    if (lowerTranscript.includes(currentWakeWord.toLowerCase())) {
      setIsAwake(true);
      haptic.medium();
      toast.info(language === 'he' ? 'ğŸ™ï¸ ××§×©×™×‘ ×œ×¤×§×•×“×”...' : 'ğŸ™ï¸ Listening for command...', { duration: 2000 });
      
      if (awakeTimeoutRef.current) clearTimeout(awakeTimeoutRef.current);
      awakeTimeoutRef.current = setTimeout(() => setIsAwake(false), 6000);
      
      const afterWakeWord = lowerTranscript.split(currentWakeWord.toLowerCase())[1]?.trim();
      if (afterWakeWord) processCommand(afterWakeWord);
      return;
    }

    if (isAwake) processCommand(lowerTranscript);
  }, [currentWakeWord, isAwake, haptic, language]);

  const processCommand = useCallback((text: string) => {
    for (const [phrase, command] of Object.entries(currentCommands)) {
      if (text.includes(phrase)) {
        setLastCommand(command);
        setIsAwake(false);
        haptic.success();
        onCommand(command);
        toast.success(COMMAND_LABELS[command][language], { duration: 2000 });
        
        if (awakeTimeoutRef.current) clearTimeout(awakeTimeoutRef.current);
        return;
      }
    }
    
    toast.info(
      language === 'he' 
        ? `×¤×§×•×“×” ×œ× ××•×›×¨×ª: "${text}"` 
        : `Command not recognized: "${text}"`, 
      { duration: 2000 }
    );
  }, [onCommand, haptic, currentCommands, language]);

  const startListening = useCallback(() => {
    if (!isSupported) {
      toast.error(language === 'he' ? '×¤×§×•×“×•×ª ×§×•×œ×™×•×ª ×œ× × ×ª××›×•×ª' : 'Voice commands not supported');
      return;
    }

    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = language === 'he' ? 'he-IL' : 'en-US';

      recognitionRef.current.onresult = (event) => {
        const last = event.results.length - 1;
        const transcript = event.results[last][0].transcript;
        if (event.results[last].isFinal) processTranscript(transcript);
      };

      recognitionRef.current.onerror = (event) => {
        console.error('Speech error:', event.error);
        if (event.error === 'not-allowed') {
          toast.error(language === 'he' ? '×’×™×©×” ×œ××™×§×¨×•×¤×•×Ÿ × ×“×—×ª×”' : 'Microphone access denied');
          setIsListening(false);
        }
      };

      recognitionRef.current.onend = () => {
        if (isListening && recognitionRef.current) recognitionRef.current.start();
      };

      recognitionRef.current.start();
      setIsListening(true);
      haptic.light();
      toast.success(
        language === 'he' 
          ? 'ğŸ™ï¸ ×¤×§×•×“×•×ª ×§×•×œ×™×•×ª ×¤×¢×™×œ×•×ª - ×××•×¨ "×”×™×™ ×¡×™××"'
          : 'ğŸ™ï¸ Voice commands active - Say "Hey CM"', 
        { duration: 3000 }
      );
    } catch (error) {
      console.error('Speech recognition error:', error);
      toast.error(language === 'he' ? '× ×›×©×œ ×‘×”×¤×¢×œ×ª ×¤×§×•×“×•×ª ×§×•×œ×™×•×ª' : 'Failed to start voice commands');
    }
  }, [isSupported, isListening, processTranscript, haptic, language]);

  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
    setIsListening(false);
    setIsAwake(false);
    haptic.light();
  }, [haptic]);

  const toggleLanguage = useCallback(() => {
    const wasListening = isListening;
    if (wasListening) stopListening();
    
    setLanguage(prev => {
      const newLang = prev === 'en' ? 'he' : 'en';
      toast.info(newLang === 'he' ? 'ğŸ‡®ğŸ‡± ×¢×‘×¨×™×ª' : 'ğŸ‡ºğŸ‡¸ English', { duration: 1500 });
      return newLang;
    });
    
    // Restart listening with new language
    setTimeout(() => {
      if (wasListening) startListening();
    }, 100);
  }, [isListening, stopListening, startListening]);

  useEffect(() => {
    return () => {
      if (recognitionRef.current) recognitionRef.current.stop();
      if (awakeTimeoutRef.current) clearTimeout(awakeTimeoutRef.current);
    };
  }, []);

  if (!isSupported) return null;

  return (
    <div className="fixed bottom-24 left-4 z-40 flex flex-col gap-2">
      {/* Language toggle */}
      <button
        onClick={toggleLanguage}
        className={cn(
          'w-10 h-10 rounded-full shadow-md flex items-center justify-center transition-all duration-200',
          'bg-card border border-border text-muted-foreground hover:bg-muted'
        )}
        aria-label={language === 'he' ? 'Switch to English' : 'Switch to Hebrew'}
      >
        <span className="text-xs font-bold">{language === 'he' ? 'EN' : '×¢×‘'}</span>
      </button>

      {/* Main voice button */}
      <button
        onClick={isListening ? stopListening : startListening}
        className={cn(
          'w-14 h-14 rounded-full shadow-lg flex items-center justify-center transition-all duration-300 touch-manipulation',
          isListening 
            ? isAwake 
              ? 'bg-jade text-white animate-pulse scale-110' 
              : 'bg-jade/80 text-white'
            : 'bg-card border border-border text-muted-foreground hover:bg-muted'
        )}
        aria-label={isListening ? 'Stop voice commands' : 'Start voice commands'}
      >
        {isListening ? (
          <div className="relative">
            <Mic className={cn('h-6 w-6', isAwake && 'animate-bounce')} />
            {isAwake && <div className="absolute -top-1 -right-1 w-3 h-3 bg-amber-400 rounded-full animate-ping" />}
          </div>
        ) : (
          <MicOff className="h-6 w-6" />
        )}
      </button>
      
      {isListening && (
        <div className="absolute -top-8 left-0 right-0 text-center whitespace-nowrap">
          <span className={cn(
            'text-[10px] px-2 py-0.5 rounded-full',
            isAwake ? 'bg-jade text-white' : 'bg-muted text-muted-foreground'
          )}>
            {isAwake 
              ? (language === 'he' ? '××§×©×™×‘...' : 'Listening...') 
              : (language === 'he' ? '×××•×¨ "×”×™×™ ×¡×™××"' : 'Say "Hey CM"')}
          </span>
        </div>
      )}

      {lastCommand && (
        <div className="absolute top-20 left-0 text-center whitespace-nowrap">
          <span className="text-[10px] px-2 py-0.5 rounded-full bg-muted/80 text-muted-foreground">
            {language === 'he' ? '××—×¨×•×Ÿ: ' : 'Last: '}{COMMAND_LABELS[lastCommand][language]}
          </span>
        </div>
      )}
    </div>
  );
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}

interface SpeechRecognitionInterface extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: (() => void) | null;
  start: () => void;
  stop: () => void;
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognitionInterface;
    webkitSpeechRecognition: new () => SpeechRecognitionInterface;
  }
}
